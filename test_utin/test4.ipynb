{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_dir = \"../mixed_data/\"\n",
    "clean_dir = \"../clean_data/\"\n",
    "nature_mixed_dir = \"../classified_sound_1115/nature/mixed/\"\n",
    "nature_clean_dir = \"../classified_sound_1115/nature/clean/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MelSpectrogram參數\n",
    "n_mels = 128                # 保持 Mel 頻譜圖的解析度\n",
    "n_fft = 1024                # 提高 FFT 窗口大小以適配更多信號頻率\n",
    "hop_length = 512            # 保持 hop_length 為 n_fft 的一半\n",
    "win_length = 1024           # 窗口大小與 n_fft 保持一致（或設為 None 使用默認值）\n",
    "sample_rate = 16000         # 採樣率保持不變，適合語音處理\n",
    "f_max = sample_rate // 2    # 預設為 Nyquist 頻率，即 8000 Hz\n",
    "duration = 5                # 音頻時長為 5 秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 0: C:\\Users\\liuut\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1\n",
      "        warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████▋⚠︎                              | (!) 1606/7499 [21%] in 10:53:57.4 (0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[43msound_to_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnature_mixed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnature_clean_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[113], line 34\u001b[0m, in \u001b[0;36msound_to_spectrogram\u001b[1;34m(mixed_dir, clean_dir, sample_rate, duration, n_mels)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 如果採樣率不匹配，進行重採樣\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;241m!=\u001b[39m sample_rate:\n\u001b[1;32m---> 34\u001b[0m     mixed_waveform \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixed_waveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     clean_waveform \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mresample(clean_waveform, orig_sr\u001b[38;5;241m=\u001b[39msr, target_sr\u001b[38;5;241m=\u001b[39msample_rate)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 如果指定了持續時間，裁剪音頻\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\librosa\\core\\audio.py:669\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[0;32m    664\u001b[0m         samplerate\u001b[38;5;241m.\u001b[39mresample, axis\u001b[38;5;241m=\u001b[39maxis, arr\u001b[38;5;241m=\u001b[39my, ratio\u001b[38;5;241m=\u001b[39mratio, converter_type\u001b[38;5;241m=\u001b[39mres_type\n\u001b[0;32m    665\u001b[0m     )\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoxr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# Use numpy to vectorize the resampler along the target axis\u001b[39;00m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;66;03m# This is because soxr does not support ndim>2 generally.\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m resampy\u001b[38;5;241m.\u001b[39mresample(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mres_type, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\_shape_base_impl.py:407\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m--> 407\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    409\u001b[0m res \u001b[38;5;241m=\u001b[39m transpose(buff, buff_permute)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(res)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\soxr\\__init__.py:206\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, in_rate, out_rate, quality)\u001b[0m\n\u001b[0;32m    203\u001b[0m q \u001b[38;5;241m=\u001b[39m _quality_to_enum(quality)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 206\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mdivide_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "\n",
    "def save_spectrogram_as_npy(spectrogram, save_path):\n",
    "    \"\"\"Save mel spectrogram as a NumPy array.\"\"\"\n",
    "    np.save(save_path, spectrogram)  # Save as .npy file\n",
    "\n",
    "def sound_to_spectrogram(mixed_dir, clean_dir, sample_rate, duration, n_mels):\n",
    "    \n",
    "    length = len([f for f in os.listdir(mixed_dir) if f != \".gitkeep\"])\n",
    "    \n",
    "    # print(f\"Loading {length} files...\")\n",
    "\n",
    "    with alive_bar(length, force_tty=True) as bar:\n",
    "        for filename in sorted(os.listdir(mixed_dir)):\n",
    "            if \".gitkeep\" in filename:\n",
    "                continue\n",
    "            try:\n",
    "                # 使用完整路徑\n",
    "                mixed_path = os.path.join(mixed_dir, filename)\n",
    "                clean_path = os.path.join(clean_dir, filename)\n",
    "                \n",
    "                # 使用 soundfile 替代 librosa.load\n",
    "                mixed_waveform, sr = sf.read(mixed_path)\n",
    "                clean_waveform, sr = sf.read(clean_path)\n",
    "                \n",
    "                # 如果採樣率不匹配，進行重採樣\n",
    "                if sr != sample_rate:\n",
    "                    mixed_waveform = librosa.resample(mixed_waveform, orig_sr=sr, target_sr=sample_rate)\n",
    "                    clean_waveform = librosa.resample(clean_waveform, orig_sr=sr, target_sr=sample_rate)\n",
    "                \n",
    "                # 如果指定了持續時間，裁剪音頻\n",
    "                if duration:\n",
    "                    samples = int(duration * sample_rate)\n",
    "                    mixed_waveform = mixed_waveform[:samples]\n",
    "                    clean_waveform = clean_waveform[:samples]\n",
    "                \n",
    "                # 生成梅爾頻譜圖\n",
    "                mixed_mel_spectrogram = librosa.feature.melspectrogram(\n",
    "                    y=mixed_waveform,\n",
    "                    sr=sample_rate,\n",
    "                    n_fft=n_fft,\n",
    "                    hop_length=hop_length,\n",
    "                    n_mels=n_mels\n",
    "                )\n",
    "                clean_mel_spectrogram = librosa.feature.melspectrogram(\n",
    "                    y=clean_waveform,\n",
    "                    sr=sample_rate,\n",
    "                    n_fft=n_fft,\n",
    "                    hop_length=hop_length,\n",
    "                    n_mels=n_mels\n",
    "                )\n",
    "\n",
    "                # 轉換為分貝刻度\n",
    "                mixed_mel_spectrogram_db = librosa.power_to_db(\n",
    "                    mixed_mel_spectrogram, \n",
    "                    ref=np.max, \n",
    "                    amin=1e-10  # 避免log(0)\n",
    "                )\n",
    "                clean_mel_spectrogram_db = librosa.power_to_db(\n",
    "                    clean_mel_spectrogram, \n",
    "                    ref=np.max, \n",
    "                    amin=1e-10\n",
    "                )\n",
    "                \n",
    "                # Save spectrograms as .npy files\n",
    "                mixed_npy_path = os.path.join(\"../nature/mixed/\", f\"{filename}_mixed.npy\")\n",
    "                clean_npy_path = os.path.join(\"../nature/clean/\", f\"{filename}_clean.npy\")\n",
    "\n",
    "                save_spectrogram_as_npy(mixed_mel_spectrogram_db, mixed_npy_path)\n",
    "                save_spectrogram_as_npy(clean_mel_spectrogram_db, clean_npy_path)\n",
    "                \n",
    "                bar()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "sound_to_spectrogram(nature_mixed_dir, nature_clean_dir, sample_rate, duration, n_mels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrogram_from_npy(mixed_dir, clean_dir):\n",
    "    \"\"\"Load mel spectrogram from a NumPy file.\"\"\"\n",
    "    mixed_mel_spectrograms = []\n",
    "    clean_mel_spectrograms = []\n",
    "    \n",
    "    length = len(os.listdir(mixed_dir))\n",
    "    \n",
    "    # print(f\"Loading {length} files...\")\n",
    "\n",
    "    with alive_bar(length, force_tty=True) as bar:\n",
    "        for filename in sorted(os.listdir(mixed_dir)):\n",
    "            if \".gitkeep\" in filename:\n",
    "                continue\n",
    "            try:\n",
    "                # 使用完整路徑\n",
    "                mixed_path = os.path.join(mixed_dir, filename)\n",
    "                clean_path = os.path.join(clean_dir, filename)\n",
    "                \n",
    "                mixed_mel_spectrogram_db = np.load(mixed_path)\n",
    "                clean_mel_spectrogram_db = np.load(clean_path)\n",
    "\n",
    "                # # 轉換為 PyTorch tensor 並添加通道維度\n",
    "                mixed_mel_tensor = torch.tensor(mixed_mel_spectrogram_db, dtype=torch.float32).unsqueeze(0)\n",
    "                clean_mel_tensor = torch.tensor(clean_mel_spectrogram_db, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "                mixed_mel_spectrograms.append(mixed_mel_tensor)\n",
    "                clean_mel_spectrograms.append(clean_mel_tensor)\n",
    "                \n",
    "                bar()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error load file {filename}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    return mixed_mel_spectrograms, clean_mel_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 0: C:\\Users\\liuut\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1\n",
      "        warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|▏⚠︎                                      | (!) 30/7499 [0%] in 11:20.0 (0.04/s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x000001B0853B2D40>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\liuut\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\liuut\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mixed_mel_spectrograms, clean_mel_spectrograms \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnature_mixed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnature_clean_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m mixed_mel_spectrograms_train, mixed_mel_spectrograms_val, clean_mel_spectrograms_train, clean_mel_spectrograms_val \u001b[38;5;241m=\u001b[39m train_test_split(mixed_mel_spectrograms, clean_mel_spectrograms, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m time_steps \u001b[38;5;241m=\u001b[39m mixed_mel_spectrograms[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "Cell \u001b[1;32mIn[108], line 33\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(mixed_dir, clean_dir, sample_rate, duration, n_mels)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 如果採樣率不匹配，進行重採樣\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;241m!=\u001b[39m sample_rate:\n\u001b[1;32m---> 33\u001b[0m     mixed_waveform \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixed_waveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     clean_waveform \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mresample(clean_waveform, orig_sr\u001b[38;5;241m=\u001b[39msr, target_sr\u001b[38;5;241m=\u001b[39msample_rate)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 如果指定了持續時間，裁剪音頻\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\librosa\\core\\audio.py:669\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[0;32m    664\u001b[0m         samplerate\u001b[38;5;241m.\u001b[39mresample, axis\u001b[38;5;241m=\u001b[39maxis, arr\u001b[38;5;241m=\u001b[39my, ratio\u001b[38;5;241m=\u001b[39mratio, converter_type\u001b[38;5;241m=\u001b[39mres_type\n\u001b[0;32m    665\u001b[0m     )\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoxr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# Use numpy to vectorize the resampler along the target axis\u001b[39;00m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;66;03m# This is because soxr does not support ndim>2 generally.\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m resampy\u001b[38;5;241m.\u001b[39mresample(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mres_type, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\_shape_base_impl.py:407\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m--> 407\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    409\u001b[0m res \u001b[38;5;241m=\u001b[39m transpose(buff, buff_permute)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(res)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\soxr\\__init__.py:206\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, in_rate, out_rate, quality)\u001b[0m\n\u001b[0;32m    203\u001b[0m q \u001b[38;5;241m=\u001b[39m _quality_to_enum(quality)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 206\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mdivide_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mixed_mel_spectrograms, clean_mel_spectrograms = load_spectrogram_from_npy(\"../nature/mixed/\", \"../nature/clean/\")\n",
    "mixed_mel_spectrograms_train, mixed_mel_spectrograms_val, clean_mel_spectrograms_train, clean_mel_spectrograms_val = train_test_split(mixed_mel_spectrograms, clean_mel_spectrograms, test_size=0.2, random_state=42)\n",
    "time_steps = mixed_mel_spectrograms[0].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiseAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoiseAutoencoder, self).__init__()\n",
    "        # 編碼器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # 解碼器\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        # Crop to match the exact target size if needed\n",
    "        if x.size(-1) > time_steps:\n",
    "            x = x[..., :time_steps]  # Crop time steps to match target (batch_size, 1, 128, 54)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model參數\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "lr_decay_step = 40\n",
    "lr_decay_gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, mixed_data, clean_data):\n",
    "        self.mixed = mixed_data\n",
    "        self.clean = clean_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mixed)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.mixed[idx], self.clean[idx]\n",
    "\n",
    "dataset = AudioDataset(mixed_mel_spectrograms_train, clean_mel_spectrograms_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "model = DenoiseAutoencoder()\n",
    "# example_input = torch.randn(1, 1, 128, time_steps)  # Batch size = 1, Channels = 1\n",
    "# output = model(example_input)\n",
    "# print(\"Output shape:\", output.shape)  # Should be (1, 1, 128, time_steps)\n",
    "\n",
    "torchsummary.summary(model,(1,64,44))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=lr_decay_step, gamma=lr_decay_gamma)\n",
    "\n",
    "# 訓練過程\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for (mixed, clean) in dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向傳播\n",
    "        outputs = model(mixed)\n",
    "        loss = criterion(outputs, clean)\n",
    "            \n",
    "        # 反向傳播和優化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Step the scheduler to decay the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Optionally, print the current learning rate and loss\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.12f}, Learning Rate: {current_lr:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfilename = \"1034-121119-0049.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN\n",
    "waveform, sample_rate = librosa.load(''.join([clean_dir, testfilename]))\n",
    "\n",
    "clean_mel = clean_mel_spectrograms[0]\n",
    "clean_output = clean_mel.squeeze(0).squeeze(0).detach().numpy()\n",
    "clean_output = librosa.db_to_power(clean_output)\n",
    "\n",
    "audio_signal = librosa.feature.inverse.mel_to_audio(clean_output, sr=sample_rate, n_iter=500)\n",
    "audio_signal = audio_signal / np.max(np.abs(audio_signal))\n",
    "\n",
    "\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "soundfile.write('test_librosa_clean.wav', audio_signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIXED\n",
    "waveform, sample_rate = librosa.load(''.join([mixed_dir, testfilename]))\n",
    "\n",
    "mixed_mel = mixed_mel_spectrograms[0]\n",
    "mixed_output = mixed_mel.squeeze(0).squeeze(0).detach().numpy()\n",
    "mixed_output = librosa.db_to_power(mixed_output)\n",
    "\n",
    "audio_signal = librosa.feature.inverse.mel_to_audio(mixed_output, sr=sample_rate, n_iter=500)\n",
    "audio_signal = audio_signal / np.max(np.abs(audio_signal))\n",
    "\n",
    "\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "soundfile.write('test_librosa_mixed.wav', audio_signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENOISED\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "denoised_output = model(mixed_mel_spectrograms[0].unsqueeze(0))\n",
    "denoised_output = denoised_output.squeeze(0).squeeze(0).detach().numpy()\n",
    "denoised_output = librosa.db_to_power(denoised_output)\n",
    "\n",
    "audio_signal = librosa.feature.inverse.mel_to_audio(denoised_output, sr=sample_rate, n_iter=500)\n",
    "audio_signal = audio_signal / np.max(np.abs(audio_signal))\n",
    "\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "soundfile.write('test_librosa_denoised.wav', audio_signal, sample_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
