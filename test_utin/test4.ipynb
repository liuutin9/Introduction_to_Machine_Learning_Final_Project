{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_dir = \"../mixed_data/\"\n",
    "clean_dir = \"../clean_data/\"\n",
    "nature_mixed_dir = \"../classified_sound_1115/nature/mixed/\"\n",
    "nature_clean_dir = \"../classified_sound_1115/nature/clean/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MelSpectrogram參數\n",
    "n_mels = 128                # 保持 Mel 頻譜圖的解析度\n",
    "n_fft = 1024                # 提高 FFT 窗口大小以適配更多信號頻率\n",
    "hop_length = 512            # 保持 hop_length 為 n_fft 的一半\n",
    "win_length = 1024           # 窗口大小與 n_fft 保持一致（或設為 None 使用默認值）\n",
    "sample_rate = 16000         # 採樣率保持不變，適合語音處理\n",
    "f_max = sample_rate // 2    # 預設為 Nyquist 頻率，即 8000 Hz\n",
    "duration = 5                # 音頻時長為 5 秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "\n",
    "# def save_spectrogram_as_npy(spectrogram, save_path):\n",
    "#     \"\"\"Save mel spectrogram as a NumPy array.\"\"\"\n",
    "#     np.save(save_path, spectrogram)  # Save as .npy file\n",
    "\n",
    "# def sound_to_spectrogram(mixed_dir, clean_dir, sample_rate, duration, n_mels):\n",
    "    \n",
    "#     length = len([f for f in os.listdir(mixed_dir) if f != \".gitkeep\"])\n",
    "    \n",
    "#     # print(f\"Loading {length} files...\")\n",
    "\n",
    "#     with alive_bar(length, force_tty=True) as bar:\n",
    "#         for filename in sorted(os.listdir(mixed_dir)):\n",
    "#             if \".gitkeep\" in filename:\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 # 使用完整路徑\n",
    "#                 mixed_path = os.path.join(mixed_dir, filename)\n",
    "#                 clean_path = os.path.join(clean_dir, filename)\n",
    "                \n",
    "#                 # 使用 soundfile 替代 librosa.load\n",
    "#                 mixed_waveform, sr = sf.read(mixed_path)\n",
    "#                 clean_waveform, sr = sf.read(clean_path)\n",
    "                \n",
    "#                 # 如果採樣率不匹配，進行重採樣\n",
    "#                 if sr != sample_rate:\n",
    "#                     mixed_waveform = librosa.resample(mixed_waveform, orig_sr=sr, target_sr=sample_rate)\n",
    "#                     clean_waveform = librosa.resample(clean_waveform, orig_sr=sr, target_sr=sample_rate)\n",
    "                \n",
    "#                 # 如果指定了持續時間，裁剪音頻\n",
    "#                 if duration:\n",
    "#                     samples = int(duration * sample_rate)\n",
    "#                     mixed_waveform = mixed_waveform[:samples]\n",
    "#                     clean_waveform = clean_waveform[:samples]\n",
    "                \n",
    "#                 # 生成梅爾頻譜圖\n",
    "#                 mixed_mel_spectrogram = librosa.feature.melspectrogram(\n",
    "#                     y=mixed_waveform,\n",
    "#                     sr=sample_rate,\n",
    "#                     n_fft=n_fft,\n",
    "#                     hop_length=hop_length,\n",
    "#                     n_mels=n_mels\n",
    "#                 )\n",
    "#                 clean_mel_spectrogram = librosa.feature.melspectrogram(\n",
    "#                     y=clean_waveform,\n",
    "#                     sr=sample_rate,\n",
    "#                     n_fft=n_fft,\n",
    "#                     hop_length=hop_length,\n",
    "#                     n_mels=n_mels\n",
    "#                 )\n",
    "\n",
    "#                 # 轉換為分貝刻度\n",
    "#                 mixed_mel_spectrogram_db = librosa.power_to_db(\n",
    "#                     mixed_mel_spectrogram, \n",
    "#                     ref=np.max, \n",
    "#                     amin=1e-10  # 避免log(0)\n",
    "#                 )\n",
    "#                 clean_mel_spectrogram_db = librosa.power_to_db(\n",
    "#                     clean_mel_spectrogram, \n",
    "#                     ref=np.max, \n",
    "#                     amin=1e-10\n",
    "#                 )\n",
    "                \n",
    "#                 # Save spectrograms as .npy files\n",
    "#                 mixed_npy_path = os.path.join(\"../nature/mixed/\", f\"{filename[-4]}.npy\")\n",
    "#                 clean_npy_path = os.path.join(\"../nature/clean/\", f\"{filename[-4]}.npy\")\n",
    "\n",
    "#                 save_spectrogram_as_npy(mixed_mel_spectrogram_db, mixed_npy_path)\n",
    "#                 save_spectrogram_as_npy(clean_mel_spectrogram_db, clean_npy_path)\n",
    "                \n",
    "#                 bar()\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing file {filename}: {str(e)}\")\n",
    "#                 continue\n",
    "            \n",
    "# sound_to_spectrogram(nature_mixed_dir, nature_clean_dir, sample_rate, duration, n_mels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrogram_from_npy(mixed_dir, clean_dir):\n",
    "    \"\"\"Load mel spectrogram from a NumPy file.\"\"\"\n",
    "    mixed_mel_spectrograms = []\n",
    "    clean_mel_spectrograms = []\n",
    "    \n",
    "    length = len(os.listdir(clean_dir))\n",
    "    \n",
    "    # print(f\"Loading {length} files...\")\n",
    "\n",
    "    with alive_bar(length, force_tty=True) as bar:\n",
    "        for filename in sorted(os.listdir(clean_dir)):\n",
    "            if \".gitkeep\" in filename:\n",
    "                continue\n",
    "            try:\n",
    "                # 使用完整路徑\n",
    "                mixed_path = os.path.join(mixed_dir, filename)\n",
    "                clean_path = os.path.join(clean_dir, filename)\n",
    "                \n",
    "                mixed_mel_spectrogram_db = np.load(mixed_path)\n",
    "                clean_mel_spectrogram_db = np.load(clean_path)\n",
    "\n",
    "                # # 轉換為 PyTorch tensor 並添加通道維度\n",
    "                mixed_mel_tensor = torch.tensor(mixed_mel_spectrogram_db, dtype=torch.float32).squeeze().unsqueeze(0)\n",
    "                clean_mel_tensor = torch.tensor(clean_mel_spectrogram_db, dtype=torch.float32).squeeze().unsqueeze(0)\n",
    "                \n",
    "                mixed_mel_spectrograms.append(mixed_mel_tensor)\n",
    "                clean_mel_spectrograms.append(clean_mel_tensor)\n",
    "                \n",
    "                bar()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error load file {filename}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    return mixed_mel_spectrograms, clean_mel_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系統找不到指定的路徑。: '../nature/clean/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mixed_mel_spectrograms, clean_mel_spectrograms \u001b[38;5;241m=\u001b[39m \u001b[43mload_spectrogram_from_npy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../nature/mixed/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../nature/clean/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m mixed_mel_spectrograms_train, mixed_mel_spectrograms_val, clean_mel_spectrograms_train, clean_mel_spectrograms_val \u001b[38;5;241m=\u001b[39m train_test_split(mixed_mel_spectrograms, clean_mel_spectrograms, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m time_steps \u001b[38;5;241m=\u001b[39m mixed_mel_spectrograms[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mload_spectrogram_from_npy\u001b[1;34m(mixed_dir, clean_dir)\u001b[0m\n\u001b[0;32m      3\u001b[0m mixed_mel_spectrograms \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m clean_mel_spectrograms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# print(f\"Loading {length} files...\")\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m alive_bar(length, force_tty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m bar:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系統找不到指定的路徑。: '../nature/clean/'"
     ]
    }
   ],
   "source": [
    "mixed_mel_spectrograms, clean_mel_spectrograms = load_spectrogram_from_npy(\"../nature/mixed/\", \"../nature/clean/\")\n",
    "mixed_mel_spectrograms_train, mixed_mel_spectrograms_val, clean_mel_spectrograms_train, clean_mel_spectrograms_val = train_test_split(mixed_mel_spectrograms, clean_mel_spectrograms, test_size=0.2, random_state=42)\n",
    "time_steps = mixed_mel_spectrograms[0].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiseAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoiseAutoencoder, self).__init__()\n",
    "        # 編碼器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # 解碼器\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        # Crop to match the exact target size if needed\n",
    "        if x.size(-1) > time_steps:\n",
    "            x = x[..., :time_steps]  # Crop time steps to match target (batch_size, 1, 128, 54)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model參數\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "lr_decay_step = 100\n",
    "lr_decay_gamma = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, mixed_data, clean_data):\n",
    "        self.mixed = mixed_data\n",
    "        self.clean = clean_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mixed)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.mixed[idx], self.clean[idx]\n",
    "\n",
    "dataset = AudioDataset(mixed_mel_spectrograms_train, clean_mel_spectrograms_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "dataloader_val = DataLoader(AudioDataset(mixed_mel_spectrograms_val, clean_mel_spectrograms_val), batch_size=len(mixed_mel_spectrograms_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "model = DenoiseAutoencoder()\n",
    "# example_input = torch.randn(1, 1, 128, time_steps)  # Batch size = 1, Channels = 1\n",
    "# output = model(example_input)\n",
    "# print(\"Output shape:\", output.shape)  # Should be (1, 1, 128, time_steps)\n",
    "\n",
    "# torchsummary.summary(model,(1,64,44))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=lr_decay_step, gamma=lr_decay_gamma)\n",
    "training_losses = []\n",
    "valdation_losses = []\n",
    "\n",
    "# 訓練過程\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for (mixed, clean) in dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向傳播\n",
    "        outputs = model(mixed)\n",
    "        loss = criterion(outputs, clean)\n",
    "            \n",
    "        # 反向傳播和優化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Step the scheduler to decay the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # count validation loss\n",
    "    val_output = model(next(iter(dataloader_val))[0])\n",
    "    val_loss = criterion(val_output, next(iter(dataloader_val))[1])\n",
    "    valdation_losses.append(val_loss.item())\n",
    "    \n",
    "    training_losses.append(loss.item())\n",
    "    # Optionally, print the current learning rate and loss\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.12f}, Validation Loss: {val_loss.item():.12f}, Learning Rate: {current_lr:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(training_losses, label=\"Training Loss\")\n",
    "plt.plot(valdation_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfilename = \"1034-121119-0049.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN\n",
    "waveform, sample_rate = librosa.load(''.join([clean_dir, testfilename]))\n",
    "\n",
    "clean_mel = clean_mel_spectrograms[0]\n",
    "clean_output = clean_mel.squeeze(0).squeeze(0).detach().numpy()\n",
    "clean_output = librosa.db_to_power(clean_output)\n",
    "\n",
    "audio_signal = librosa.feature.inverse.mel_to_audio(clean_output, sr=sample_rate, n_iter=500)\n",
    "audio_signal = audio_signal / np.max(np.abs(audio_signal))\n",
    "\n",
    "\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "soundfile.write('test_librosa_clean.wav', audio_signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIXED\n",
    "waveform, sample_rate = librosa.load(''.join([mixed_dir, testfilename]))\n",
    "\n",
    "mixed_mel = mixed_mel_spectrograms[0]\n",
    "mixed_output = mixed_mel.squeeze(0).squeeze(0).detach().numpy()\n",
    "mixed_output = librosa.db_to_power(mixed_output)\n",
    "\n",
    "audio_signal = librosa.feature.inverse.mel_to_audio(mixed_output, sr=sample_rate, n_iter=500)\n",
    "audio_signal = audio_signal / np.max(np.abs(audio_signal))\n",
    "\n",
    "\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "soundfile.write('test_librosa_mixed.wav', audio_signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENOISED\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "denoised_output = model(mixed_mel_spectrograms[0].unsqueeze(0))\n",
    "denoised_output = denoised_output.squeeze(0).squeeze(0).detach().numpy()\n",
    "denoised_output = librosa.db_to_power(denoised_output)\n",
    "\n",
    "audio_signal = librosa.feature.inverse.mel_to_audio(denoised_output, sr=sample_rate, n_iter=500)\n",
    "audio_signal = audio_signal / np.max(np.abs(audio_signal))\n",
    "\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "soundfile.write('test_librosa_denoised.wav', audio_signal, sample_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
